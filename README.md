---
title: GAIA Agent (Final Assignment of HF Agents Course)
emoji: ğŸ•µğŸ»â€â™‚ï¸
colorFrom: indigo
colorTo: indigo
sdk: gradio
sdk_version: 5.33.0
app_file: app.py
pinned: false
hf_oauth: true
# optional, default duration is 8 hours/480 minutes. Max duration is 30 days/43200 minutes.
hf_oauth_expiration_minutes: 480
---


# GAIA AI Agent via LangGraph

This repository contains a **LangGraphâ€‘powered** agent that scores over 30% on the GAIA Levelâ€‘1 benchmark *without any RAG leaks*.
It routes questions, invokes the right tool, and returns an exactâ€‘match string for the grader.

## ğŸ“œ What is GAIA?

**GAIA = _â€œGeneral AI Assistantsâ€_** â€“ a multi-domain benchmark introduced in the paper   [GAIA: A Benchmark for General AI Assistants](https://arxiv.org/abs/2311.12983).
The public leaderboard is hosted on Hugging Face:
<https://huggingface.co/spaces/gaia-benchmark/leaderboard>

---

## âœ¨Â Key features

| Capability | Implementation |
|------------|---------------|
| Multiâ€‘step routing | LangGraph state machine (`route_question â†’ invoke_tools â†’ synthesize_response â†’ format_output`) |
| Web & Wiki search | Tavily âœ DuckDuckGo fallback |
| YouTube | `youtube_transcript_api` âœ generate captions |
| Spreadsheets | `analyze_excel_file` (*pandas* oneâ€‘liner generator) |
| Attached code | Safe `subprocess` sandbox via `run_py` |
| Audio | OpenAIâ€‘Whisper |
| Vision | VLM (GPT-4o-mini)|

---

## ğŸ“‚Â Repository guide

| File | Purpose |
|------|---------|
| `app.py` | Gradio UI, API submission, LangGraph workflow |
| `tools.py` | All custom LangChain tools (search, Excel, Whisper, *etc*.) |
| `prompts.yaml` | LLM prompts |
| `helpers.py` | Tiny utilities (debug prints *etc*.) |
| `debug_agent.py` | Run agent on a single GAIA question from CLI |
| `requirements.txt` | Runtime deps |
| `requirements-dev.txt` | Dev / lint deps |

---

## ğŸš€Â Quick start

    # clone repo / space
    pip install -r requirements.txt   # PythonÂ â‰¥Â 3.11
    python app.py                     # launches local Gradio UI

Run **one** task from CLI (handy while tuning prompts):

    python debug_agent.py <GAIA_task_id>

### Environment variables

| Var | Used for | Example |
|-----|----------|---------|
| `OPENAI_API_KEY` | Router & answer LLM (OpenAI) | `skâ€‘â€¦` |
| `TAVILY_API_KEY` | Higherâ€‘quality web search (optional) | `tvly_â€¦` |

*(Agent falls back to DuckDuckGo if `TAVILY_API_KEY` is absent.)*

---

##  Agent Routing & Tool-Execution Flow


![GAIA  Agent Routing & Tool-Execution Flow](agent_routing_architecture.png)

- **route_question**â€‚routes to one of eight labels.
- **invoke_tools**â€‚invokes the matching tool and stores context.
- **synthesize_response**â€‚calls the answer LLM unless the answer was computed.
- **format_output**â€‚normalizes output for GAIAâ€™s exactâ€‘match scorer.


## ğŸ“ Prompt snippet

All LLM prompts are available in `prompts.yaml`:

## ğŸ› ï¸ Dev helpers

1ï¸âƒ£ Create the virtual environment and activate it.

```
uv venv --python 3.11
source ./.venv/bin/activate
```

2ï¸âƒ£ Install Python dependencies:

```
uv pip install -r requirements.txt
uv pip install -r requirements-dev.txt
```

3ï¸âƒ£ [Optional] Install Git hooks for code quality checks :

```
pre-commit install
```
